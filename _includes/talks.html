<!-- <section id="contact" class="container contact-section text-center"> -->

<section id="talks" class="content-section">
  <div class="container about-section">
    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <br>
        <h2 class="text-center">Talks</h2>
        <div class="col-lg-8 col-lg-offset-2">


          <h4> Yao Xie </h4>
          <p> Hypothesis tests via distributionally robust optimization</p>
          <p><a href="yao.pdf">Slides</a> &nbsp; <a
              href="https://www.youtube.com/watch?v=VKHe6ACvvIk&list=PLTPQEx-31JXjFCL_rRIJP2C4Qmg7Pd0dE">Video</a></p>
          We consider a general data-driven robust hypothesis test formulation to find an optimal test (function) that
          minimizes the worst-case performance regarding distributions that are close to the empirical distributions
          with respect to some divergence, in particular, the Wasserstein and the sink horn divergences. The robust
          tests are beneficial, for instance, for cases with limited or unbalanced samples - such a scenario often
          arises from applications such as health care, online change-point detection, and anomaly detection. We present
          a distributionally robust optimization framework to solve such a problem and study the computational and
          statistical properties of the proposed test by presenting a tractable convex reformulation of the original
          infinite-dimensional variational problem. Finally, I will present the generalization of the approach to other
          related problems, including domain adaptation.
          <br><br><br>

          <h4>Samory Kpotufe</h4>
          <p> Tracking Most Significant Arm Switches in Bandits </p>
          <p><a href="">Slides</a> &nbsp; <a
              href="https://www.youtube.com/watch?v=65ze1eVCg7g&list=PLTPQEx-31JXjFCL_rRIJP2C4Qmg7Pd0dE&index=2">Video</a>
          </p>
          In bandit with distribution shifts, one aims to automatically adapt to unknown changes in reward distribution,
          and restart exploration when necessary. While this problem has received attention for many years, no adaptive
          procedure was known till a recent breakthrough of Auer et al (2018, 2019) which guarantees an optimal
          (dynamic) regret (LT)^{1/2}, for T rounds and L stationary phases.
          <br><br>
          However, while this rate is tight in the worst case, it leaves open whether faster rates are possible,
          adaptively, if few changes in distribution are actually severe, e.g., involve no change in best arm. We
          provide a positive answer, showing that in fact, a much weaker notion of change can be adapted to, which can
          yield significantly faster rates than previously known, whether as expressed in terms of number of best arm
          switches--for which no adaptive procedure was known, or in terms of total variation. Finally, our
          parametrization captures at once, both stochastic and non-stochastic adversarial settings.
          <br><br><br>


          <h4>Ludwig Schmidt</h4>
          <p> A data-centric view on robustness</p>
          <p><a href="ludwig.pdf">Slides</a> &nbsp; <a
              href="https://www.youtube.com/watch?v=1Pm8NnCSACY&list=PLTPQEx-31JXjFCL_rRIJP2C4Qmg7Pd0dE&index=3">Video</a>
          </p>
          Over the past few years, researchers have proposed many ways to measure the robustness of machine learning
          models. In the first part of the talk, we will survey the current robustness landscape based on a large-scale
          experimental study involving more than 200 different models and test conditions. Despite the large variety of
          test conditions, common trends emerge: (i) robustness to natural distribution shift and synthetic
          perturbations are distinct phenomena, (ii) current algorithmic techniques have little effect on robustness to
          natural distribution shifts, (iii) training on more diverse datasets offers robustness gains on several
          natural distribution shifts.
          <br><br>
          In the second part of the talk, we then leverage the aforementioned insights to improve OpenAI’s CLIP model.
          CLIP achieved unprecedented robustness on several natural distribution shifts, but only when used as a
          zero-shot model. The zero-shot evaluation precludes the use of extra data for fine-tuning and hence leads to
          lower performance when there is a specific task of interest. To address this issue, we introduce a simple yet
          effective method for fine-tuning zero-shot models that leads to large robustness gains on several distribution
          shifts without reducing in-distribution performance.
          <br><br><br>

          <h4>Jamie Morgenstern</h4>
          <p>Endogeneous distribution shifts in competitive environments</p>
          <p><a href="talks/jamie.pdf">Slides</a> &nbsp; <a
              href="https://www.youtube.com/watch?v=9-0UU9nU8RA&list=PLTPQEx-31JXjFCL_rRIJP2C4Qmg7Pd0dE&index=4">Video</a>
          </p>
          In this talk, I'll describe recent work exploring the dynamics between ML systems and the populations they
          serve, particularly when the models deployed impact what populations a system will have as future customers.
          <br><br><br>

          <h4>Hongseok Namkoong</h4>
          <p>Assessing the external validity (a.k.a. distributional robustness) of causal findings</p>
          <p><a href="hong.pdf">Slides</a> &nbsp; <a
              href="https://drive.google.com/file/d/1ApBFWEkzOP39gIVMDBnXbdXXlARWXqDX/view?usp=sharing">Video</a></p>
          Causal inference—analyzing the ceteris paribus effect of an intervention—is key to reliable decision-making.
          Due to population shifts over time and underrepresentation of marginalized groups, standard causal estimands
          that measure the average treatment effect often lose validity outside the study population. To guarantee that
          causal findings remain valid over population shifts, we propose the worst-case treatment effect (WTE) across
          all subpopulations of a given size. We develop an optimal estimator for the WTE based on flexible prediction
          methods, which allows analyzing the external validity of the popular doubly robust estimator. On real examples
          where external validity is of core concern, our proposed framework successfully guards against brittle
          findings that are invalidated under unanticipated population shifts.
          <br><br><br>

          <h4>Aditi Raghunathan</h4>
          <p>Estimating and improving the performance of machine learning under natural distribution shifts</p>
          <p><a href="">Slides</a> &nbsp; <a
              href="https://drive.google.com/file/d/1Br94E23iVNpTHrGhsGqo68Gr1VQVAu2u/view?usp=sharing">Video</a></p>
          Machine learning systems often fail catastrophically under the presence of distribution shift—when the test
          distribution differs in some systematic way from the training distribution. If we can mathematically
          characterize a distribution shift, we could devise appropriate robust training algorithms that promote
          robustness to that specific class of shifts. However, the resulting robust models show limited gains on shifts
          that do not admit the structure they were specifically trained against. Naturally occurring shifts are both
          hard to predict a priori and intractable to mathematically characterize necessitating different approaches to
          addressing distribution shifts in the wild.
          <br><br>
          In this talk, we first discuss how to estimate the performance of models under natural distribution shifts—the
          shift could cause a small degradation or a catastrophic drop. Obtaining ground truth labels is expensive and
          requires the a priori knowledge of when and what kind of distribution shifts are likely to occur. We present a
          phenomenon that we call agreement-on-the-line that allows us to effectively predict performance under
          distribution shift from just unlabeled data. Next, we investigate a promising avenue for improving robustness
          to natural shifts—leveraging representations pre-trained on diverse data. Via theory and experiments, we find
          that the de facto fine-tuning of pre-trained representations does not maximally preserve robustness. Using
          insights from our analysis, we provide two simple alternate fine-tuning approaches that substantially boost
          robustness to natural shifts.
          <br><br><br>

          <h4>Terry Rockafellar</h4>
          <p>Robustness from the Perspective of Coherent Measures of Risk</p>
          <p><a href="talks/terry.pdf">Slides</a> &nbsp; <a
              href="https://drive.google.com/file/d/1DEOCTq_hmGeqS1lrOH49yWZJRvHwZvDv/view?usp=sharing">Video</a></p>
          Measures of risk seek to quantify the overall "risk" in a cost- or loss-oriented random variable by a single
          value, such as its expectation or worst outcome, or better, something in between.Common sense axioms were
          developed for this in the late 90s by mathematicians working in finance, and they used the term "coherent" for
          the risk measures that satisfied those axioms. Their work was soon broadened, and it was established by way of
          duality in convex analysis that coherent measures of risk correspond exactly to looking for robustness with
          respect to some collection of alternative probability distributions.
          <br><br>
          The theory has since become highly developed with powerful approaches to quantification like conditional
          value-at-risk and others based on that. Now also, it includes interesting connections with statistics and
          regression captured by the "fundamental quadrangle of risk", as will be explained in this talk, with examples.
          <br><br><br>

          <h4>Stephen J. Wright</h4>
          <p>Robust formulations and algorithms for learning problems under distributional ambiguity</p>
          <p><a href="talks/steve.pdf">Slides</a> &nbsp; <a
              href="https://drive.google.com/file/d/1I7j3NHm8_WDZjzgmqYdJxu-FxlNwuqMK/view?usp=sharing">Video</a></p>
          We discuss learning problems in which the empirical distribution represented by the training data is used to
          define an ambiguous set of distributions, and we seek the classifier or regressor that solves a min-max
          problem involving this set. Our focus is mainly on linear models. First, we discuss formulation of the robust
          min-max problem based on classification with the discontinuous "zero-one" loss function, using Wasserstein
          ambiguity, and describe properties of the resulting nonconvex problem, which is benignly nonconvex in a
          certain sense. Second, we discuss robust formulations of convex ERM problems involving linear models, where
          the distributional ambiguity is measured using either a Wasserstein metric or f-divergence. We show that such
          problems can be formulated as "generalized linear programs" and solved using a first-order primal-dual
          algorithm that incorporates coordinate descent in the dual variable and variance reduction. We present
          numerical results to illustrate properties of the robust optimization formulations and algorithms.
          <br><br><br>

          <h4>Brian Ziebart</h4>
          <p>Prediction Games: From Maximum Likelihood Estimation to Active Learning, Fair Machine Learning, and
            Structured Prediction</p>
          <p><a href="talks/brian.pdf">Slides</a> &nbsp; <a
              href="https://drive.google.com/file/d/1QQPO_2OEHzD6N1euUC--Bc6zpdiJ43EO/view?usp=sharing">Video</a></p>
          A standard approach to supervised machine learning is to choose the form of a predictor and to then optimize
          its parameters based on training data. Approximations of the predictor's performance measure are often
          required to make this optimization problem tractable. Instead of approximating the performance measure and
          using the exact training data, this talk explores a distributionally robust approach using game-theoretic
          approximations of the training data while optimizing the exact performance measures of interest. Though the
          resulting "prediction games" reduce to maximum likelihood estimation in simple cases, they provide new methods
          for more complicated prediction tasks involving covariate shift, fairness constraint satisfaction, and
          structured data.
          <br><br><br>

          <h4>Friday Short Talks and Demos</h4>
          <p><a href="talks/friday_short_talks.pdf">Slides</a> &nbsp; <a href="">Video</a></p>
          <ul>
            <li><b>Shiori Sagawa</b>: Extending the WILDS Benchmark for Unsupervised Adaptation</li>
            <li><b>Ananya Kumar</b>: Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain
              Adaptation</li>
            <li><b>Josh Gardner</b>: Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation</li>
            <li><b>Sushrut Karmalkar</b>: Robust Sparse Mean Estimation via Sum of Squares</li>
            <li><b>Mitchell Wortsman</b>: <a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a> Software
              Demo (<a href="talks/mitchell_software.pdf">Slides</a>)</li>
            <li><b>Yassine Laguel</b>: <a href="https://yassine-laguel.github.io/spqr/">SPQR</a> Software Demo</li>
            <li><b>Krishna Pillutla</b>: <a href="https://krishnap25.github.io/sqwash/">SQwash</a> Software Demo (<a
                href="https://colab.research.google.com/drive/1GApiM0AsMb6Zw1O4dgL5iGRlWlsIaH6s?usp=sharing">Colab</a>)
            </li>
          </ul>

          <br><br>

          <h4>Saturday Short Talks</h4>
          <p><a href="talks/saturday_short_talks.pdf">Slides</a> &nbsp; <a
              href="https://drive.google.com/drive/folders/1esU0qiSBEXsRLQGeu7Wij7nhPIlPN3lq?usp=sharing">Videos</a></p>
          <ul>
            <li><b>Krishna Pillutla</b>: Tackling distribution shifts in federated learning</li>
            <li><b>Ahmet Alacaoglu</b>: On the Complexity of a Practical Primal-Dual Coordinate Method</li>
            <li><b>Lijun Ding</b>: Flat Minima Generalize for Low-rank Matrix Recovery</li>
            <li><b>Zaid Harchaoui</b>: Stochastic Optimization Under Time Drift </li>
            <li><b>Yassine Laguel</b>: Chance Constrained Problems: a Bilevel Convex Optimization Perspective</li>
            <li><b>Lang Liu</b>: Orthogonal Statistical Learning with Self-Concordant Loss</li>
          </ul>
          </ul>

        </div>
      </div>
      <!--     ### The following lines are not required for the last tab -->
      <div class="text-center">
        <a href="#contact" class="btn btn-circle page-scroll">
          <i class="fa fa-angle-double-down animated"></i>
        </a>
      </div>
    </div>
</section>